# -*- coding: utf-8 -*-
"""AIM-model training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wA4pzXJRY6N_LXJZLa33CuTRQPCYlkGc
"""

# Commented out IPython magic to ensure Python compatibility.
# %rm -rf midi/

import numpy
import glob
import pickle
from keras.utils import np_utils
from music21 import converter, note, chord
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import *
from keras.callbacks import ModelCheckpoint

note_list = []
for midi in glob.glob('midi_files/<GENRE>/*.mid'):
    song = converter.parse(midi)
    flat_elements = song.flat.notes
    for e in flat_elements:
        if isinstance(e, note.Note):
            note_list.append(str(e.pitch))
        elif isinstance(e, chord.Chord):
            note_list.append("+".join(str(a) for a in e.normalOrder))

with open("<GENRE>_total_notes", 'wb') as filepath:
    pickle.dump(note_list, filepath)
with open("<GENRE>_total_notes", 'rb') as f:
    total_notes = pickle.load(f)

unique_notes = len(set(total_notes))
print(f"Unique notes: {unique_notes}")

sequence_length = 100
pitches = sorted(set(total_notes))
elem_to_num = dict((e, n) for n, e in enumerate(pitches))
_input = []
output = []

for x in range(len(total_notes) - sequence_length):
    sequence_input = total_notes[x:x + sequence_length]
    sequence_output = total_notes[x + sequence_length]
    _input.append([elem_to_num[char] for char in sequence_input])
    output.append(elem_to_num[sequence_output])

patterns = len(_input)
_input = numpy.reshape(_input, (patterns, sequence_length, 1))
input_normalized = _input / float(unique_notes)
output = np_utils.to_categorical(output)

model = Sequential()
model.add(LSTM(units=512,
               input_shape=(input_normalized.shape[1], input_normalized.shape[2]),
               return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(512, return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(512))
model.add(Dropout(0.3))
model.add(Dense(256))
model.add(Dropout(0.3))
model.add(Dense(unique_notes, activation="softmax"))
model.compile(loss="categorical_crossentropy", optimizer="adam")

checkpoint = ModelCheckpoint("<GENRE>_model.hdf5", monitor='loss', verbose=0, save_best_only=True, mode='min')
model_his = model.fit(input_normalized, output, epochs=100, batch_size=128, callbacks=[checkpoint])

epochs = range(1, 101)

plt.plot(epochs, model_his.history['loss'])
plt.title('Training loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.show()
